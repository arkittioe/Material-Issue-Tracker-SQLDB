# file: MIGRATE_SPOOL.py (ØªØ§Ø¨Ø¹ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡)

import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from models import Spool, SpoolItem, Base
import numpy as np  # <-- Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©Ø±Ø¯Ù† numpy Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² np.nan

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
DB_PATH = "sqlite:///miv_registry.db"
SPOOLS_CSV_PATH = "Spools.csv"
SPOOL_ITEMS_CSV_PATH = "SpoolItems.csv"


def import_data():
    """
    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ø®ÙˆØ§Ù†Ø¯Ù‡ Ùˆ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    engine = create_engine(DB_PATH)
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    session = Session()

    print("âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´Ø¯.")

    try:
        # --------------------------------------------------
        # Ù…Ø±Ø­Ù„Ù‡ Û±: Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Spools (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
        # --------------------------------------------------
        print(f"\n Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {SPOOLS_CSV_PATH}...")
        spools_df = pd.read_csv(SPOOLS_CSV_PATH)
        spool_id_map = {}

        print("Ø¯Ø± Ø­Ø§Ù„ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¬Ø¯ÙˆÙ„ 'spools'...")
        for index, row in spools_df.iterrows():
            new_spool = Spool(
                spool_id=row['SPOOL_ID'],
                row_no=row['Row_No'],
                line_no=row['Line_No'],
                sheet_no=row['Sheet_No'],
                location=row['Location'],
                command=row['Command']
            )
            session.add(new_spool)
            session.flush()
            spool_id_map[new_spool.spool_id] = new_spool.id
        print(f"âœ”ï¸ {len(spools_df)} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ù‡ Ø¬Ø¯ÙˆÙ„ 'spools' Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

        # --------------------------------------------------
        # Ù…Ø±Ø­Ù„Ù‡ Û²: Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ SpoolItems
        # --------------------------------------------------
        print(f"\n Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {SPOOL_ITEMS_CSV_PATH}...")
        items_df = pd.read_csv(SPOOL_ITEMS_CSV_PATH)
        items_df.rename(columns={'ITEMCODE': 'item_code'}, inplace=True)

        # --- Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ ---
        # Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø§Ø´Ù†Ø¯
        numeric_cols = ['P1_Bore', 'P2_Bore', 'Thickness', 'Length', 'Qty_Available']

        print("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ...")
        for col in numeric_cols:
            # pd.to_numeric Ù‡Ø± Ù…Ù‚Ø¯Ø§Ø±ÛŒ Ø±Ø§ Ú©Ù‡ Ù†ØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø¹Ø¯Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ø¯ (Ù…Ø«Ù„ '-')
            # Ø¨Ø§ NaN (Not a Number) Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
            # Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ù‚Ø¯Ø§Ø± NaN Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† NULL Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ ØµØ­ÛŒØ­ Ø§Ø³Øª.
            items_df[col] = pd.to_numeric(items_df[col], errors='coerce')

        # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø¯Ø± Ú©Ù„ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ø§ None ØªØ§ Ø¨Ø±Ø§ÛŒ SQLAlchemy Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯
        items_df = items_df.replace({np.nan: None})

        # -------------------------------------------

        print("Ø¯Ø± Ø­Ø§Ù„ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¬Ø¯ÙˆÙ„ 'spool_items'...")
        # Ø­Ø§Ù„Ø§ Ø§Ø² to_dict Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        items_to_insert = items_df.to_dict(orient='records')

        items_added_count = 0
        items_skipped_count = 0

        for row in items_to_insert:
            spool_csv_id = row['Spool_ID']
            spool_db_id = spool_id_map.get(spool_csv_id)

            if spool_db_id:
                new_item = SpoolItem(
                    spool_id_fk=spool_db_id,
                    component_type=row['Component_Type'],
                    class_angle=row['Class_Angle'],
                    p1_bore=row['P1_Bore'],
                    p2_bore=row['P2_Bore'],
                    material=row['Material'],
                    schedule=row['Schedule'],
                    thickness=row['Thickness'],
                    length=row['Length'],
                    qty_available=row['Qty_Available'],
                    item_code=row['item_code']
                )
                session.add(new_item)
                items_added_count += 1
            else:
                print(f"âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: Ø§Ø³Ù¾ÙˆÙ„ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù‡ '{spool_csv_id}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² Ø§ÛŒÙ† Ø¢ÛŒØªÙ… ØµØ±Ùâ€ŒÙ†Ø¸Ø± Ø´Ø¯.")
                items_skipped_count += 1

        print(f"âœ”ï¸ {items_added_count} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø±Ø§ÛŒ Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ù‡ 'spool_items' Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯.")
        if items_skipped_count > 0:
            print(f"âš ï¸ {items_skipped_count} Ø±Ú©ÙˆØ±Ø¯ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")

        session.commit()
        print("\nğŸ‰ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ù†ØªÙ‚Ù„ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")

    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø§! Ø¹Ù…Ù„ÛŒØ§Øª Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ù‡ Ø­Ø§Ù„Øª Ù‚Ø¨Ù„ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ø´Ø¯.")
        print(f"   Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§: {e}")
        session.rollback()
    finally:
        session.close()
        print("... Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø³ØªÙ‡ Ø´Ø¯.")


if __name__ == '__main__':
    import_data()